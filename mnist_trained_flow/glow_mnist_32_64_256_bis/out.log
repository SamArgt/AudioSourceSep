TensorFlow version: 2.2.0
Eager execution: True
Glow Bijector 2 Blocks: 
	 K = 32 
	 ShiftAndLogScaleResNet 
	 n_filters = 64 
	 batch size = 256
flow sample shape:  (1, 28, 28, 1)
Total Trainable Variables:  957312
Start Training on 300 epochs
Epoch 000: Loss: 103275785355264.000
Epoch 003: Loss: 77813833728.000
Epoch 006: Loss: 30279903232.000
Epoch 009: Loss: 17521119232.000
Epoch 012: Loss: 11085310976.000
Epoch 015: Loss: 5417339392.000
Epoch 018: Loss: 2704415488.000
Epoch 021: Loss: 1361290240.000
Epoch 024: Loss: 488077568.000
Epoch 027: Loss: 249232640.000
Epoch 030: Loss: 162359664.000
Epoch 033: Loss: 81736616.000
Epoch 036: Loss: 33090758.000
Epoch 039: Loss: 18975764.000
Epoch 042: Loss: 13618250.000
Epoch 045: Loss: 10353005.000
Epoch 048: Loss: 7811220.000
Epoch 051: Loss: 5590377.000
Epoch 054: Loss: 3819673.000
Epoch 057: Loss: 2450285.750
Epoch 060: Loss: 1466408.750
Epoch 063: Loss: 662287.688
Epoch 066: Loss: 373856.469
Epoch 069: Loss: 282068.969
Epoch 072: Loss: 221119.750
Epoch 075: Loss: 175062.031
Epoch 078: Loss: 139973.047
Epoch 081: Loss: 109459.820
Epoch 084: Loss: 85043.414
Epoch 087: Loss: 66053.055
Epoch 090: Loss: 50879.289
Epoch 093: Loss: 39248.402
Epoch 096: Loss: 29982.711
Epoch 099: Loss: 22696.389
Epoch 102: Loss: 17183.502
Epoch 105: Loss: 13293.814
Epoch 108: Loss: 10504.298
Epoch 111: Loss: 8480.245
Epoch 114: Loss: 7010.199
Epoch 117: Loss: 5951.979
Epoch 120: Loss: 5205.350
Epoch 123: Loss: 4710.352
Epoch 126: Loss: 4394.113
Epoch 129: Loss: 4178.381
Epoch 132: Loss: 4022.622
Epoch 135: Loss: 3892.712
Epoch 138: Loss: 3783.017
Epoch 141: Loss: 3666.471
Epoch 144: Loss: 3541.022
Epoch 147: Loss: 3372.033
Epoch 150: Loss: 3203.122
Epoch 153: Loss: 2961.881
Epoch 156: Loss: 2551.656
Epoch 159: Loss: 1140.901
Epoch 162: Loss: 725.295
Epoch 165: Loss: 480.903
Epoch 168: Loss: 300.796
Epoch 171: Loss: 150.162
Epoch 174: Loss: 29.090
Epoch 177: Loss: -61.063
Model Saved at ./tf_ckpts/ckpt-1
Epoch 180: Loss: -135.655
Model Saved at ./tf_ckpts/ckpt-2
Epoch 183: Loss: 279555.688
Epoch 186: Loss: 179263.016
Epoch 189: Loss: 131600.281
Epoch 192: Loss: 80004.273
Epoch 195: Loss: 57789.176
Epoch 198: Loss: 44859.566
Epoch 201: Loss: 34421.496
Epoch 204: Loss: 26509.316
Epoch 207: Loss: 20079.729
Epoch 210: Loss: 16469.359
Epoch 213: Loss: 13315.438
Epoch 216: Loss: 11926.261
Epoch 219: Loss: 15486.393
Epoch 222: Loss: 12642.777
Epoch 225: Loss: 11217.828
Epoch 228: Loss: 10371.093
Epoch 231: Loss: 9639.793
Epoch 234: Loss: 9113.052
Epoch 237: Loss: 8190.623
Epoch 240: Loss: 7688.735
Epoch 243: Loss: 6575.650
Epoch 246: Loss: 229202575360.000
Epoch 249: Loss: 255149.359
Epoch 252: Loss: 216447.625
Epoch 255: Loss: 116841.555
Epoch 258: Loss: 50044.805
Epoch 261: Loss: 38896.875
Epoch 264: Loss: 31939.361
Epoch 267: Loss: 28275.500
Epoch 270: Loss: 26448.305
Epoch 273: Loss: 23827.422
Epoch 276: Loss: 22360.141
Epoch 279: Loss: 19997.764
Epoch 282: Loss: 18689.967
Epoch 285: Loss: 17949.754
Epoch 288: Loss: 16739.572
Epoch 291: Loss: 55447.125
Epoch 294: Loss: 28530.627
Epoch 297: Loss: 21656.312
Model Saved at ./tf_ckpts/ckpt-3
Training time:  21056.75  seconds
loss history saved
9 samples saved
